name: kinc CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  test-baked-in:
    runs-on: ubuntu-latest
    name: Test (baked-in config)
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: System prerequisites check
        run: |
          echo "=== System Prerequisites Check ==="
          
          # IP forwarding
          echo "━━━ Check 1: IP Forwarding ━━━"
          if [ "$(cat /proc/sys/net/ipv4/ip_forward)" != "1" ]; then
            echo "Enabling IP forwarding..."
            echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward
          fi
          echo "✅ IP forwarding: enabled"
          echo ""
          
          # Inotify limits
          echo "━━━ Check 2: Inotify Limits ━━━"
          echo "  Current max_user_watches:   $(cat /proc/sys/fs/inotify/max_user_watches)"
          echo "  Current max_user_instances: $(cat /proc/sys/fs/inotify/max_user_instances)"
          echo "Setting inotify limits for multi-cluster testing..."
          echo 524288 | sudo tee /proc/sys/fs/inotify/max_user_watches > /dev/null
          echo 2048 | sudo tee /proc/sys/fs/inotify/max_user_instances > /dev/null
          echo "✅ Inotify limits: configured (watches=524288, instances=2048)"
          echo ""
          
          # Kernel keyring limits
          echo "━━━ Check 3: Kernel Keyring Limits ━━━"
          echo "  Current maxkeys:   $(cat /proc/sys/kernel/keys/maxkeys 2>/dev/null || echo 'N/A')"
          echo "  Current maxbytes:  $(cat /proc/sys/kernel/keys/maxbytes 2>/dev/null || echo 'N/A')"
          echo "Setting kernel keyring limits for multi-cluster testing..."
          echo 1000 | sudo tee /proc/sys/kernel/keys/maxkeys > /dev/null
          echo 25000 | sudo tee /proc/sys/kernel/keys/maxbytes > /dev/null
          echo "✅ Kernel keyring limits: configured (maxkeys=1000, maxbytes=25000)"
          echo ""
          
          # Failed services
          echo "━━━ Check 4: System Health ━━━"
          failed=$(systemctl --user list-units --state=failed --no-pager --no-legend 2>/dev/null | wc -l)
          if [ $failed -gt 0 ]; then
            echo "⚠️  Found $failed failed services"
            systemctl --user list-units --state=failed --no-pager
          else
            echo "✅ No failed services"
          fi
          echo ""
          
          # Podman
          echo "━━━ Check 5: Podman ━━━"
          echo "✅ Podman: $(podman --version)"
          echo ""
          
          echo "✅ Prerequisites check complete"
        shell: bash

      - name: Build kinc image
        run: |
          echo "=== Building kinc image with multi-service architecture ==="
          ./tools/build.sh
          echo "✅ Image built successfully"
        shell: bash

      - name: Deploy cluster (baked-in config)
        run: |
          echo "=== Deploying cluster with baked-in configuration ==="
          
          export CLUSTER_NAME=default
          export USE_BAKED_IN_CONFIG=true
          export KINC_ENABLE_FARO=true
          
          # Deploy using systemd-driven approach
          ./tools/deploy.sh
          
          echo "✅ Deployment initiated"
        shell: bash

      - name: Wait for cluster initialization (systemd-driven)
        run: |
          echo "=== Waiting for Cluster Initialization ==="
          echo "Multi-service architecture: kinc-preflight → kubeadm-init → kinc-postinit"
          echo ""
          
          max_wait=300
          waited=0
          
          while [ $waited -lt $max_wait ]; do
            # Check if container is running
            if ! podman ps --filter "name=kinc-default-control-plane" --format "{{.Names}}" | grep -q "kinc-default-control-plane"; then
              echo "❌ Container not running"
              systemctl --user status kinc-default-control-plane.service --no-pager || true
              exit 1
            fi
            
            # Check if initialization complete
            if podman exec kinc-default-control-plane test -f /var/lib/kinc-initialized 2>/dev/null; then
              echo "✅ Cluster initialized (${waited}s)"
              break
            fi
            
            # Check if any service failed
            if podman exec kinc-default-control-plane systemctl is-failed --quiet kinc-preflight.service 2>/dev/null || \
               podman exec kinc-default-control-plane systemctl is-failed --quiet kubeadm-init.service 2>/dev/null || \
               podman exec kinc-default-control-plane systemctl is-failed --quiet kinc-postinit.service 2>/dev/null; then
              echo "❌ One or more services failed"
              echo ""
              echo "Service status:"
              podman exec kinc-default-control-plane systemctl status kinc-preflight.service --no-pager || true
              podman exec kinc-default-control-plane systemctl status kubeadm-init.service --no-pager || true
              podman exec kinc-default-control-plane systemctl status kinc-postinit.service --no-pager || true
              exit 1
            fi
            
            if [ $((waited % 30)) -eq 0 ] && [ $waited -gt 0 ]; then
              echo "  Still initializing... (${waited}/${max_wait}s)"
            fi
            
            sleep 5
            waited=$((waited + 5))
          done
          
          if [ $waited -ge $max_wait ]; then
            echo "❌ Timeout waiting for initialization"
            exit 1
          fi
          
          echo ""
          echo "✅ Initialization complete"
        shell: bash

      - name: Verify multi-service architecture
        run: |
          echo "=== Verifying Multi-Service Architecture ==="
          
          # Check all services completed successfully
          echo "Checking kinc-preflight.service..."
          if ! podman exec kinc-default-control-plane systemctl is-active --quiet kinc-preflight.service; then
            echo "❌ kinc-preflight.service not active"
            podman exec kinc-default-control-plane systemctl status kinc-preflight.service --no-pager
            exit 1
          fi
          echo "✅ kinc-preflight.service: active"
          
          echo "Checking kubeadm-init.service..."
          if ! podman exec kinc-default-control-plane systemctl is-active --quiet kubeadm-init.service; then
            echo "❌ kubeadm-init.service not active"
            podman exec kinc-default-control-plane systemctl status kubeadm-init.service --no-pager
            exit 1
          fi
          echo "✅ kubeadm-init.service: active (kubeadm as systemd service)"
          
          echo "Checking kinc-postinit.service..."
          if ! podman exec kinc-default-control-plane systemctl is-active --quiet kinc-postinit.service; then
            echo "❌ kinc-postinit.service not active"
            podman exec kinc-default-control-plane systemctl status kinc-postinit.service --no-pager
            exit 1
          fi
          echo "✅ kinc-postinit.service: active"
          
          # Verify initialization marker
          if ! podman exec kinc-default-control-plane test -f /var/lib/kinc-initialized; then
            echo "❌ Initialization marker not found"
            exit 1
          fi
          echo "✅ Initialization marker: /var/lib/kinc-initialized"
          
          # Verify kubeadm marker
          if ! podman exec kinc-default-control-plane test -f /var/lib/kubeadm-initialized; then
            echo "❌ kubeadm initialization marker not found"
            exit 1
          fi
          echo "✅ kubeadm marker: /var/lib/kubeadm-initialized"
          
          echo ""
          echo "✅ Multi-service architecture verified"
        shell: bash

      - name: Verify baked-in configuration
        run: |
          echo "=== Verifying Baked-In Configuration ==="
          
          # Check kinc-preflight.service logs for config source
          config_source=$(podman exec kinc-default-control-plane journalctl -u kinc-preflight.service --no-pager --boot 2>/dev/null | grep -oP '(Using mounted configuration|No mounted config found, using baked-in configuration)' | head -1)
          
          echo "Configuration source: $config_source"
          
          if [[ "$config_source" == *"baked-in"* ]]; then
            echo "✅ Using baked-in config as expected"
          else
            echo "❌ NOT using baked-in config"
            echo ""
            echo "kinc-preflight.service logs:"
            podman exec kinc-default-control-plane journalctl -u kinc-preflight.service --no-pager --boot 2>/dev/null || true
            exit 1
          fi
        shell: bash

      - name: Verify configuration validation
        run: |
          echo "=== Verifying Configuration Validation ==="
          
          # Check kinc-preflight completed config validation
          if ! podman exec kinc-default-control-plane journalctl -u kinc-preflight.service --no-pager --boot | grep -q "Configuration validated"; then
            echo "❌ Configuration validation not found in kinc-preflight.service logs"
            exit 1
          fi
          echo "✅ Configuration validated by kinc-preflight.service"
          
          # Verify kubeadm-init completed successfully
          # Note: We skip the show-join-command phase, so check for addon installation instead
          if ! podman exec kinc-default-control-plane journalctl -u kubeadm-init.service --no-pager --boot | grep -q "Applied essential addon: kube-proxy"; then
            echo "❌ kubeadm init did not complete successfully"
            exit 1
          fi
          echo "✅ kubeadm init completed successfully (as systemd service)"
          
          # Verify CNI installation by kinc-postinit
          if ! podman exec kinc-default-control-plane journalctl -u kinc-postinit.service --no-pager --boot | grep "Installing CNI" >/dev/null 2>&1; then
            echo "❌ CNI installation not found in kinc-postinit.service logs"
            echo "Full kinc-postinit logs:"
            podman exec kinc-default-control-plane journalctl -u kinc-postinit.service --no-pager --boot
            exit 1
          fi
          echo "✅ CNI installed by kinc-postinit.service"
          
          echo ""
          echo "✅ All configuration validations passed"
        shell: bash

      - name: Extract kubeconfig and validate cluster
        run: |
          echo "=== Extracting kubeconfig ==="
          mkdir -p ~/.kube
          
          # Get cluster port
          cluster_port=$(podman inspect kinc-default-control-plane --format '{{range $p, $conf := .NetworkSettings.Ports}}{{range $conf}}{{.HostPort}}{{end}}{{end}}' 2>/dev/null)
          echo "Cluster port: $cluster_port"
          
          # Extract and configure kubeconfig
          podman cp kinc-default-control-plane:/etc/kubernetes/admin.conf ~/.kube/config
          sed -i "s|server: https://.*:6443|server: https://127.0.0.1:$cluster_port|g" ~/.kube/config
          
          echo "✅ Kubeconfig ready"
          echo ""
          
          echo "=== Validating Cluster ==="
          
          echo "Cluster info:"
          kubectl cluster-info
          
          echo ""
          echo "Nodes:"
          kubectl get nodes -o wide
          
          echo ""
          echo "All pods:"
          kubectl get pods -A -o wide
          
          echo ""
          echo "Services:"
          kubectl get svc -A
          
          echo ""
          echo "✅ Cluster validated"
        shell: bash

      - name: Collect comprehensive diagnostics
        if: always()
        run: |
          echo "=== Collecting Comprehensive Diagnostics ==="
          mkdir -p artifacts/logs
          
          # Host-side diagnostics
          echo "Collecting host-side diagnostics..."
          systemctl --user status kinc-default-control-plane.service --no-pager > artifacts/systemd-status.txt 2>&1 || true
          journalctl --user -xeu kinc-default-control-plane.service --no-pager > artifacts/systemd-logs.txt 2>&1 || true
          
          # Container-side multi-service logs (from boot)
          echo "Collecting multi-service logs from boot..."
          podman exec kinc-default-control-plane journalctl -u kinc-preflight.service --no-pager --boot > artifacts/logs/kinc-preflight.log 2>&1 || true
          podman exec kinc-default-control-plane journalctl -u kubeadm-init.service --no-pager --boot > artifacts/logs/kubeadm-init.log 2>&1 || true
          podman exec kinc-default-control-plane journalctl -u kinc-postinit.service --no-pager --boot > artifacts/logs/kinc-postinit.log 2>&1 || true
          podman exec kinc-default-control-plane journalctl -u crio.service --no-pager --boot > artifacts/logs/crio.log 2>&1 || true
          podman exec kinc-default-control-plane journalctl -u kubelet.service --no-pager --boot > artifacts/logs/kubelet.log 2>&1 || true
          podman exec kinc-default-control-plane journalctl --no-pager --boot > artifacts/logs/system-full.log 2>&1 || true
          
          # Service status summary
          echo "Collecting service status summary..."
          {
            echo "=== Multi-Service Architecture Status ==="
            echo ""
            echo "━━━ kinc-preflight.service ━━━"
            podman exec kinc-default-control-plane systemctl status kinc-preflight.service --no-pager 2>&1 || true
            echo ""
            echo "━━━ kubeadm-init.service ━━━"
            podman exec kinc-default-control-plane systemctl status kubeadm-init.service --no-pager 2>&1 || true
            echo ""
            echo "━━━ kinc-postinit.service ━━━"
            podman exec kinc-default-control-plane systemctl status kinc-postinit.service --no-pager 2>&1 || true
          } > artifacts/service-status.txt
          
          # Kubernetes diagnostics
          echo "Collecting Kubernetes diagnostics..."
          kubectl cluster-info dump > artifacts/cluster-info.txt 2>&1 || true
          kubectl get all -A > artifacts/resources.txt 2>&1 || true
          kubectl get events -A --sort-by='.lastTimestamp' > artifacts/events.txt 2>&1 || true
          
          # Network diagnostics
          echo "Collecting network diagnostics..."
          podman ps --all > artifacts/containers.txt 2>&1 || true
          podman port kinc-default-control-plane > artifacts/port-mapping.txt 2>&1 || true
          podman inspect kinc-default-control-plane > artifacts/container-inspect.json 2>&1 || true
          
          echo "✅ Diagnostics collection complete"
          echo ""
          echo "Collected files:"
          ls -lh artifacts/
          ls -lh artifacts/logs/
        shell: bash

      - name: Upload diagnostics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: kinc-diagnostics-baked-in-${{ github.run_number }}
          path: artifacts/
          retention-days: 30

      - name: Extract Faro events
        if: always()
        run: |
          echo "=== Extracting Faro Events ==="
          
          # Extract directly from data volume (no podman exec needed)
          FARO_PATH="$HOME/.local/share/containers/storage/volumes/kinc-default-var-data/_data/lib/kinc/faro-events/logs"
          
          if [ -d "$FARO_PATH" ] && [ -n "$(ls -A $FARO_PATH/*.json 2>/dev/null)" ]; then
            echo "✅ Faro events found in data volume"
            
            mkdir -p artifacts/faro
            
            # Copy events from volume
            cp $FARO_PATH/*.json artifacts/faro/ 2>/dev/null || true
            cp $FARO_PATH/*.log artifacts/faro/ 2>/dev/null || true
            
            # Count events
            EVENT_COUNT=$(cat artifacts/faro/*.json 2>/dev/null | wc -l)
            echo "✅ Captured $EVENT_COUNT events"
            
            # Show summary
            echo ""
            echo "Event Summary:"
            cat artifacts/faro/*.json | jq -r '.gvr' | sort | uniq -c | sort -rn | head -10
          else
            echo "⚠️  Faro events not found - skipping extraction"
          fi
        shell: bash

      - name: Upload Faro events
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: faro-events-baked-in-${{ github.run_number }}
          path: artifacts/faro/
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          echo "=== Cleaning up ==="
          ./tools/cleanup.sh default || true
          systemctl --user reset-failed || true
          echo "✅ Cleanup complete"
        shell: bash

  test-mounted:
    runs-on: ubuntu-latest
    name: Test (mounted config)
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: System prerequisites check
        run: |
          echo "=== System Prerequisites Check ==="
          
          # IP forwarding
          echo "━━━ Check 1: IP Forwarding ━━━"
          if [ "$(cat /proc/sys/net/ipv4/ip_forward)" != "1" ]; then
            echo "Enabling IP forwarding..."
            echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward
          fi
          echo "✅ IP forwarding: enabled"
          echo ""
          
          # Inotify limits
          echo "━━━ Check 2: Inotify Limits ━━━"
          echo "  Current max_user_watches:   $(cat /proc/sys/fs/inotify/max_user_watches)"
          echo "  Current max_user_instances: $(cat /proc/sys/fs/inotify/max_user_instances)"
          echo "Setting inotify limits for multi-cluster testing..."
          echo 524288 | sudo tee /proc/sys/fs/inotify/max_user_watches > /dev/null
          echo 2048 | sudo tee /proc/sys/fs/inotify/max_user_instances > /dev/null
          echo "✅ Inotify limits: configured (watches=524288, instances=2048)"
          echo ""
          
          # Kernel keyring limits
          echo "━━━ Check 3: Kernel Keyring Limits ━━━"
          echo "  Current maxkeys:   $(cat /proc/sys/kernel/keys/maxkeys 2>/dev/null || echo 'N/A')"
          echo "  Current maxbytes:  $(cat /proc/sys/kernel/keys/maxbytes 2>/dev/null || echo 'N/A')"
          echo "Setting kernel keyring limits for multi-cluster testing..."
          echo 1000 | sudo tee /proc/sys/kernel/keys/maxkeys > /dev/null
          echo 25000 | sudo tee /proc/sys/kernel/keys/maxbytes > /dev/null
          echo "✅ Kernel keyring limits: configured (maxkeys=1000, maxbytes=25000)"
          echo ""
          
          # Failed services
          echo "━━━ Check 4: System Health ━━━"
          failed=$(systemctl --user list-units --state=failed --no-pager --no-legend 2>/dev/null | wc -l)
          if [ $failed -gt 0 ]; then
            echo "⚠️  Found $failed failed services"
            systemctl --user list-units --state=failed --no-pager
          else
            echo "✅ No failed services"
          fi
          echo ""
          
          # Podman
          echo "━━━ Check 5: Podman ━━━"
          echo "✅ Podman: $(podman --version)"
          echo ""
          
          echo "✅ Prerequisites check complete"
        shell: bash

      - name: Build kinc image
        run: |
          echo "=== Building kinc image with multi-service architecture ==="
          ./tools/build.sh
          echo "✅ Image built successfully"
        shell: bash

      - name: Deploy clusters (mounted config)
        run: |
          echo "=== Deploying 2 clusters with mounted configuration ==="
          echo "This demonstrates multi-cluster capability with mounted configs"
          echo ""
          
          # Deploy cluster 1
          echo "Deploying cluster: default (port 6443)"
          export CLUSTER_NAME=default
          export KINC_ENABLE_FARO=true
          ./tools/deploy.sh
          echo "✅ Cluster 'default' deployment initiated"
          echo ""
          
          # Deploy cluster 2
          echo "Deploying cluster: cluster01 (port 6444)"
          export CLUSTER_NAME=cluster01
          export KINC_ENABLE_FARO=true
          ./tools/deploy.sh
          echo "✅ Cluster 'cluster01' deployment initiated"
          echo ""
          
          echo "✅ Both cluster deployments initiated"
        shell: bash

      - name: Wait for clusters initialization (systemd-driven)
        run: |
          echo "=== Waiting for Both Clusters Initialization ==="
          echo "Multi-service architecture: kinc-preflight → kubeadm-init → kinc-postinit"
          echo ""
          
          for cluster in default cluster01; do
            echo "Waiting for cluster: $cluster"
            max_wait=300
            waited=0
            
            while [ $waited -lt $max_wait ]; do
              # Check if container is running
              if ! podman ps --filter "name=kinc-${cluster}-control-plane" --format "{{.Names}}" | grep -q "kinc-${cluster}-control-plane"; then
                echo "❌ Container not running: kinc-${cluster}-control-plane"
                systemctl --user status kinc-${cluster}-control-plane.service --no-pager || true
                exit 1
              fi
              
              # Check if initialization complete
              if podman exec kinc-${cluster}-control-plane test -f /var/lib/kinc-initialized 2>/dev/null; then
                echo "✅ Cluster '$cluster' initialized (${waited}s)"
                break
              fi
              
              # Check if any service failed
              if podman exec kinc-${cluster}-control-plane systemctl is-failed --quiet kinc-preflight.service 2>/dev/null || \
                 podman exec kinc-${cluster}-control-plane systemctl is-failed --quiet kubeadm-init.service 2>/dev/null || \
                 podman exec kinc-${cluster}-control-plane systemctl is-failed --quiet kinc-postinit.service 2>/dev/null; then
                echo "❌ One or more services failed in cluster '$cluster'"
                echo ""
                echo "Service status:"
                podman exec kinc-${cluster}-control-plane systemctl status kinc-preflight.service --no-pager || true
                podman exec kinc-${cluster}-control-plane systemctl status kubeadm-init.service --no-pager || true
                podman exec kinc-${cluster}-control-plane systemctl status kinc-postinit.service --no-pager || true
                exit 1
              fi
              
              if [ $((waited % 30)) -eq 0 ] && [ $waited -gt 0 ]; then
                echo "  Still initializing cluster '$cluster'... (${waited}/${max_wait}s)"
              fi
              
              sleep 5
              waited=$((waited + 5))
            done
            
            if [ $waited -ge $max_wait ]; then
              echo "❌ Timeout waiting for cluster '$cluster' initialization"
              exit 1
            fi
            
            echo ""
          done
          
          echo "✅ Both clusters initialized successfully"
        shell: bash

      - name: Verify multi-service architecture (both clusters)
        run: |
          echo "=== Verifying Multi-Service Architecture (Both Clusters) ==="
          
          for cluster in default cluster01; do
            echo ""
            echo "Checking cluster: $cluster"
            
            # Check all services completed successfully
            echo "Checking kinc-preflight.service..."
            if ! podman exec kinc-${cluster}-control-plane systemctl is-active --quiet kinc-preflight.service; then
              echo "❌ kinc-preflight.service not active in cluster '$cluster'"
              podman exec kinc-${cluster}-control-plane systemctl status kinc-preflight.service --no-pager
              exit 1
            fi
            echo "✅ kinc-preflight.service: active"
            
            echo "Checking kubeadm-init.service..."
            if ! podman exec kinc-${cluster}-control-plane systemctl is-active --quiet kubeadm-init.service; then
              echo "❌ kubeadm-init.service not active in cluster '$cluster'"
              podman exec kinc-${cluster}-control-plane systemctl status kubeadm-init.service --no-pager
              exit 1
            fi
            echo "✅ kubeadm-init.service: active (kubeadm as systemd service)"
            
            echo "Checking kinc-postinit.service..."
            if ! podman exec kinc-${cluster}-control-plane systemctl is-active --quiet kinc-postinit.service; then
              echo "❌ kinc-postinit.service not active in cluster '$cluster'"
              podman exec kinc-${cluster}-control-plane systemctl status kinc-postinit.service --no-pager
              exit 1
            fi
            echo "✅ kinc-postinit.service: active"
            
            # Verify initialization marker
            if ! podman exec kinc-${cluster}-control-plane test -f /var/lib/kinc-initialized; then
              echo "❌ Initialization marker not found in cluster '$cluster'"
              exit 1
            fi
            echo "✅ Initialization marker: /var/lib/kinc-initialized"
            
            # Verify kubeadm marker
            if ! podman exec kinc-${cluster}-control-plane test -f /var/lib/kubeadm-initialized; then
              echo "❌ kubeadm initialization marker not found in cluster '$cluster'"
              exit 1
            fi
            echo "✅ kubeadm marker: /var/lib/kubeadm-initialized"
            
            echo "✅ Cluster '$cluster': Multi-service architecture verified"
          done
          
          echo ""
          echo "✅ Multi-service architecture verified for both clusters"
        shell: bash

      - name: Verify mounted configuration (both clusters)
        run: |
          echo "=== Verifying Mounted Configuration (Both Clusters) ==="
          
          for cluster in default cluster01; do
            echo ""
            echo "Checking cluster: $cluster"
            
            # Check kinc-preflight.service logs for config source
            config_source=$(podman exec kinc-${cluster}-control-plane journalctl -u kinc-preflight.service --no-pager --boot 2>/dev/null | grep -oP '(Using mounted configuration|No mounted config found, using baked-in configuration)' | head -1)
            
            echo "Configuration source: $config_source"
            
            if [[ "$config_source" == *"mounted"* ]]; then
              echo "✅ Cluster '$cluster': Using mounted config as expected"
            else
              echo "❌ Cluster '$cluster': NOT using mounted config"
              echo ""
              echo "kinc-preflight.service logs:"
              podman exec kinc-${cluster}-control-plane journalctl -u kinc-preflight.service --no-pager --boot 2>/dev/null || true
              exit 1
            fi
          done
          
          echo ""
          echo "✅ Both clusters using mounted configuration"
        shell: bash

      - name: Verify configuration validation (both clusters)
        run: |
          echo "=== Verifying Configuration Validation (Both Clusters) ==="
          
          for cluster in default cluster01; do
            echo ""
            echo "Checking cluster: $cluster"
            
            # Check kinc-preflight completed config validation
            if ! podman exec kinc-${cluster}-control-plane journalctl -u kinc-preflight.service --no-pager --boot | grep -q "Configuration validated"; then
              echo "❌ Configuration validation not found in cluster '$cluster'"
              exit 1
            fi
            echo "✅ Configuration validated by kinc-preflight.service"
            
            # Verify kubeadm-init completed successfully
            # Note: We skip the show-join-command phase, so check for addon installation instead
            if ! podman exec kinc-${cluster}-control-plane journalctl -u kubeadm-init.service --no-pager --boot | grep -q "Applied essential addon: kube-proxy"; then
              echo "❌ kubeadm init did not complete successfully in cluster '$cluster'"
              exit 1
            fi
            echo "✅ kubeadm init completed successfully (as systemd service)"
            
            # Verify CNI installation by kinc-postinit
            if ! podman exec kinc-${cluster}-control-plane journalctl -u kinc-postinit.service --no-pager --boot | grep "Installing CNI" >/dev/null 2>&1; then
              echo "❌ CNI installation not found in cluster '$cluster'"
              echo "Full kinc-postinit logs:"
              podman exec kinc-${cluster}-control-plane journalctl -u kinc-postinit.service --no-pager --boot
              exit 1
            fi
            echo "✅ CNI installed by kinc-postinit.service"
            
            echo "✅ Cluster '$cluster': All configuration validations passed"
          done
          
          echo ""
          echo "✅ Both clusters configuration validated"
        shell: bash

      - name: Extract kubeconfig and validate clusters
        run: |
          echo "=== Extracting kubeconfig and Validating Both Clusters ==="
          mkdir -p ~/.kube
          
          for cluster in default cluster01; do
            echo ""
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            echo "Cluster: $cluster"
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            
            # Get cluster port
            cluster_port=$(podman inspect kinc-${cluster}-control-plane --format '{{range $p, $conf := .NetworkSettings.Ports}}{{range $conf}}{{.HostPort}}{{end}}{{end}}' 2>/dev/null)
            echo "Cluster port: $cluster_port"
            
            # Extract and configure kubeconfig
            podman cp kinc-${cluster}-control-plane:/etc/kubernetes/admin.conf ~/.kube/kinc-${cluster}-config
            sed -i "s|server: https://.*:6443|server: https://127.0.0.1:$cluster_port|g" ~/.kube/kinc-${cluster}-config
            
            echo "✅ Kubeconfig ready: ~/.kube/kinc-${cluster}-config"
            echo ""
            
            export KUBECONFIG=~/.kube/kinc-${cluster}-config
            
            echo "Cluster info:"
            kubectl cluster-info
            
            echo ""
            echo "Nodes:"
            kubectl get nodes -o wide
            
            echo ""
            echo "All pods:"
            kubectl get pods -A -o wide
            
            echo ""
            echo "Services:"
            kubectl get svc -A
            
            echo ""
            echo "✅ Cluster '$cluster' validated"
          done
          
          echo ""
          echo "✅ Both clusters validated successfully"
        shell: bash

      - name: Collect comprehensive diagnostics
        if: always()
        run: |
          echo "=== Collecting Comprehensive Diagnostics (Both Clusters) ==="
          mkdir -p artifacts/logs
          
          for cluster in default cluster01; do
            echo "Collecting diagnostics for cluster: $cluster"
            mkdir -p artifacts/${cluster}/logs
            
            # Host-side diagnostics
            echo "Collecting host-side diagnostics..."
            systemctl --user status kinc-${cluster}-control-plane.service --no-pager > artifacts/${cluster}/systemd-status.txt 2>&1 || true
            journalctl --user -xeu kinc-${cluster}-control-plane.service --no-pager > artifacts/${cluster}/systemd-logs.txt 2>&1 || true
            
            # Container-side multi-service logs (from boot)
            echo "Collecting multi-service logs from boot..."
            podman exec kinc-${cluster}-control-plane journalctl -u kinc-preflight.service --no-pager --boot > artifacts/${cluster}/logs/kinc-preflight.log 2>&1 || true
            podman exec kinc-${cluster}-control-plane journalctl -u kubeadm-init.service --no-pager --boot > artifacts/${cluster}/logs/kubeadm-init.log 2>&1 || true
            podman exec kinc-${cluster}-control-plane journalctl -u kinc-postinit.service --no-pager --boot > artifacts/${cluster}/logs/kinc-postinit.log 2>&1 || true
            podman exec kinc-${cluster}-control-plane journalctl -u crio.service --no-pager --boot > artifacts/${cluster}/logs/crio.log 2>&1 || true
            podman exec kinc-${cluster}-control-plane journalctl -u kubelet.service --no-pager --boot > artifacts/${cluster}/logs/kubelet.log 2>&1 || true
            podman exec kinc-${cluster}-control-plane journalctl --no-pager --boot > artifacts/${cluster}/logs/system-full.log 2>&1 || true
            
            # Service status summary
            echo "Collecting service status summary..."
            {
              echo "=== Multi-Service Architecture Status: $cluster ==="
              echo ""
              echo "━━━ kinc-preflight.service ━━━"
              podman exec kinc-${cluster}-control-plane systemctl status kinc-preflight.service --no-pager 2>&1 || true
              echo ""
              echo "━━━ kubeadm-init.service ━━━"
              podman exec kinc-${cluster}-control-plane systemctl status kubeadm-init.service --no-pager 2>&1 || true
              echo ""
              echo "━━━ kinc-postinit.service ━━━"
              podman exec kinc-${cluster}-control-plane systemctl status kinc-postinit.service --no-pager 2>&1 || true
            } > artifacts/${cluster}/service-status.txt
            
            # Kubernetes diagnostics
            echo "Collecting Kubernetes diagnostics..."
            export KUBECONFIG=~/.kube/kinc-${cluster}-config
            kubectl cluster-info dump > artifacts/${cluster}/cluster-info.txt 2>&1 || true
            kubectl get all -A > artifacts/${cluster}/resources.txt 2>&1 || true
            kubectl get events -A --sort-by='.lastTimestamp' > artifacts/${cluster}/events.txt 2>&1 || true
            
            # Network diagnostics
            echo "Collecting network diagnostics..."
            podman port kinc-${cluster}-control-plane > artifacts/${cluster}/port-mapping.txt 2>&1 || true
            podman inspect kinc-${cluster}-control-plane > artifacts/${cluster}/container-inspect.json 2>&1 || true
            
            echo "✅ Diagnostics collected for cluster: $cluster"
          done
          
          # Collect podman ps for all clusters
          podman ps --all > artifacts/containers.txt 2>&1 || true
          
          echo "✅ Diagnostics collection complete"
          echo ""
          echo "Collected files:"
          find artifacts/ -type f
        shell: bash

      - name: Upload diagnostics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: kinc-diagnostics-mounted-${{ github.run_number }}
          path: artifacts/
          retention-days: 30

      - name: Extract Faro events from both clusters
        if: always()
        run: |
          echo "=== Extracting Faro Events from Both Clusters ==="
          
          mkdir -p artifacts/faro
          
          for cluster in default cluster01; do
            echo ""
            echo "Extracting events from cluster: $cluster"
            
            # Extract directly from data volume (no podman exec needed)
            FARO_PATH="$HOME/.local/share/containers/storage/volumes/kinc-${cluster}-var-data/_data/lib/kinc/faro-events/logs"
            
            if [ -d "$FARO_PATH" ] && [ -n "$(ls -A $FARO_PATH/*.json 2>/dev/null)" ]; then
              echo "✅ Faro events found in $cluster data volume"
              
              # Copy events from volume
              cp $FARO_PATH/*.json artifacts/faro/bootstrap-events-${cluster}.json 2>/dev/null || true
              cp $FARO_PATH/*.log artifacts/faro/bootstrap-logs-${cluster}.log 2>/dev/null || true
              
              # Count events
              EVENT_COUNT=$(cat artifacts/faro/bootstrap-events-${cluster}.json 2>/dev/null | wc -l)
              echo "✅ Captured $EVENT_COUNT events from $cluster"
              
              # Show summary
              echo "Event Summary for $cluster:"
              cat artifacts/faro/bootstrap-events-${cluster}.json | jq -r '.gvr' | sort | uniq -c | sort -rn | head -5
            else
              echo "⚠️  Faro events not found in $cluster - skipping extraction"
            fi
          done
          
          echo ""
          echo "✅ Faro event extraction complete for all clusters"
        shell: bash

      - name: Upload Faro events
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: faro-events-mounted-${{ github.run_number }}
          path: artifacts/faro/
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          echo "=== Cleaning up both clusters ==="
          ./tools/cleanup.sh default || true
          ./tools/cleanup.sh cluster01 || true
          systemctl --user reset-failed || true
          echo "✅ Cleanup complete"
        shell: bash

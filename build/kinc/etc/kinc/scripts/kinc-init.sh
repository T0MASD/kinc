#!/bin/bash
set -euo pipefail

echo "=== kinc Kind-Free Initialization Starting ==="

# Wait for basic systemd services (not full system-running state to avoid circular dependency)
echo "Waiting for basic systemd services..."
sleep 5

# Wait for CRI-O to be ready
echo "Waiting for CRI-O to be ready..."
while ! systemctl is-active crio.service >/dev/null 2>&1; do
    echo "Waiting for CRI-O service..."
    sleep 2
done

# Wait for CRI-O socket
echo "Waiting for CRI-O socket..."
while ! test -S /var/run/crio/crio.sock; do
    echo "Waiting for CRI-O socket..."
    sleep 2
done

# Test CRI-O connectivity
echo "Testing CRI-O connectivity..."
                                                crictl --runtime-endpoint unix:///var/run/crio/crio.sock version

# Get container IP address
CONTAINER_IP=$(ip route get 1.1.1.1 | awk '{print $7; exit}')
echo "Detected container IP: $CONTAINER_IP"

# Template the kubeadm config with the actual container IP
sed "s/CONTAINER_IP_PLACEHOLDER/$CONTAINER_IP/g" /etc/kinc/config/kubeadm.conf > /tmp/kubeadm-final.conf

# Initialize Kubernetes cluster
echo "Initializing Kubernetes cluster with kubeadm..."
kubeadm init --config=/tmp/kubeadm-final.conf --skip-phases=preflight

# Kubelet configuration is now correctly generated by kubeadm from kubeadm.conf
echo "✅ Kubelet configured for rootless operation via kubeadm config"

# Patch kube-proxy to remove privileged flag for rootless operation
echo "Patching kube-proxy DaemonSet to remove privileged flag..."
kubectl --kubeconfig=/etc/kubernetes/admin.conf patch daemonset kube-proxy -n kube-system --type='json' -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/securityContext/privileged", "value": false}]'
echo "✅ kube-proxy patched for rootless operation"

# Wait for API server to be fully ready before installing any manifests
echo "Waiting for API server to be ready..."
while ! kubectl --kubeconfig=/etc/kubernetes/admin.conf get --raw=/healthz >/dev/null 2>&1; do
    echo "Waiting for API server to respond..."
    sleep 2
done

# Additional check: ensure API server can handle requests properly
echo "Verifying API server functionality..."
kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes >/dev/null 2>&1 || {
    echo "API server not fully ready, waiting..."
    sleep 5
    kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes >/dev/null 2>&1
}

echo "✅ API server is ready and responsive"

# Install CNI (using kinc's default CNI with proper templating)
echo "Installing CNI..."
if [ -f /kinc/manifests/default-cni.yaml ]; then
    # Template the CNI manifest with our pod subnet (matching kubeadm config)
    sed 's/{{ \.PodSubnet }}/10.244.0.0\/16/g' /kinc/manifests/default-cni.yaml > /tmp/cni-manifest.yaml
    kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /tmp/cni-manifest.yaml
    echo "✅ CNI installed successfully"
else
    echo "❌ CNI manifest not found at /kinc/manifests/default-cni.yaml"
fi

# Wait for CNI to be ready before proceeding
echo "Waiting for CNI pods to be ready..."
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready pods -l k8s-app=kincnet -n kube-system --timeout=120s || {
    echo "⚠️  CNI pods not ready yet, but continuing..."
}

# Wait for nodes to be ready first
echo "Waiting for node to be ready..."
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready nodes --all --timeout=300s

# Wait for control plane pods to be fully ready and stable
echo "Waiting for control plane to be completely stable..."
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready pod -l component=etcd -n kube-system --timeout=120s
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready pod -l component=kube-apiserver -n kube-system --timeout=120s
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready pod -l component=kube-controller-manager -n kube-system --timeout=120s
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready pod -l component=kube-scheduler -n kube-system --timeout=120s

# Additional stability check - ensure all control plane components are stable
echo "Verifying control plane stability..."
sleep 5

# Remove control plane taint so storage provisioner can be scheduled
kubectl --kubeconfig=/etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule- || true

# Now install storage class with fully stable control plane
echo "Installing storage class..."
if [ -f /kinc/manifests/default-storage.yaml ]; then
    kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /kinc/manifests/default-storage.yaml
    echo "✅ Storage class installed successfully"
else
    echo "❌ Storage manifest not found at /kinc/manifests/default-storage.yaml"
fi

# Wait for storage provisioner to be ready
echo "Waiting for storage provisioner to be ready..."
kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Available deployment/local-path-provisioner -n local-path-storage --timeout=120s || {
    echo "⚠️  Storage provisioner not ready yet, but continuing..."
}

echo "=== kinc Kind-Free Initialization Complete ==="
echo "Cluster is ready!"

# Signal that initialization is complete
touch /var/lib/kinc-initialized

echo "=== Continuing with normal systemd operation ==="
